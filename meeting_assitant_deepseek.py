import requests
import gradio as gr
import sounddevice as sd
import numpy as np
import os
import tempfile
import json
import time
from datetime import datetime

# DeepSeek API é…ç½®
DEEPSEEK_API_KEY = "your_api_key_here"  # æ›¿æ¢ä¸ºæ‚¨çš„APIå¯†é’¥
SPEECH_API_URL = "https://api.deepseek.com/v1/audio/transcriptions"
CHAT_API_URL = "https://api.deepseek.com/v1/chat/completions"

# å…¨å±€å˜é‡
is_recording = False
meeting_data = {
    "transcript": "",
    "start_time": "",
    "speakers": [],
    "key_points": [],
    "action_items": []
}

def transcribe_audio(audio_path):
    """ä½¿ç”¨DeepSeekè¯­éŸ³è¯†åˆ«APIè½¬å†™éŸ³é¢‘"""
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "multipart/form-data"
    }
    
    with open(audio_path, "rb") as audio_file:
        files = {"file": (os.path.basename(audio_path), audio_file, "audio/wav")}
        data = {"model": "deepseek-vl"}
        
        response = requests.post(SPEECH_API_URL, headers=headers, files=files, data=data)
    
    if response.status_code == 200:
        result = response.json()
        return result.get("text", "")
    else:
        print(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {response.status_code} - {response.text}")
        return ""

def deepseek_chat(prompt, system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹", model="deepseek-chat"):
    """è°ƒç”¨DeepSeekæ–‡æœ¬ç”ŸæˆAPI"""
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7,
        "max_tokens": 2000
    }
    
    response = requests.post(CHAT_API_URL, headers=headers, json=payload)
    
    if response.status_code == 200:
        result = response.json()
        return result["choices"][0]["message"]["content"]
    else:
        print(f"æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {response.status_code} - {response.text}")
        return ""

def record_audio(duration=60, sample_rate=16000):
    """å½•åˆ¶éŸ³é¢‘"""
    print(f"å¼€å§‹å½•éŸ³ï¼Œæ—¶é•¿: {duration}ç§’...")
    audio = sd.rec(int(duration * sample_rate), 
                   samplerate=sample_rate, channels=1)
    sd.wait()
    print("å½•éŸ³ç»“æŸ")
    
    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    audio.tofile(temp_file.name)
    return temp_file.name

def process_meeting(audio_path=None, live_audio=None):
    """å¤„ç†ä¼šè®®å½•éŸ³"""
    global meeting_data
    
    # é‡ç½®ä¼šè®®æ•°æ®
    meeting_data = {
        "transcript": "",
        "start_time": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "speakers": [],
        "key_points": [],
        "action_items": []
    }
    
    # è·å–éŸ³é¢‘å†…å®¹
    if audio_path:
        # å¤„ç†ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        transcript = transcribe_audio(audio_path)
    elif live_audio:
        # å¤„ç†å®æ—¶å½•éŸ³
        with open(live_audio, "wb") as f:
            f.write(live_audio)
        transcript = transcribe_audio(live_audio)
    else:
        return "é”™è¯¯: æœªæä¾›éŸ³é¢‘è¾“å…¥", ""
    
    meeting_data["transcript"] = transcript
    
    # ç”Ÿæˆä¼šè®®æ‘˜è¦
    summary_prompt = f"""
    è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®è®°å½•ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦ï¼š
    
    ## è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
    - ä¸»è¦å‚ä¼šäººå‘˜: [åˆ—å‡ºä¸»è¦å‘è¨€äºº]
    - æ ¸å¿ƒè®®é¢˜: [åˆ—å‡º3-5ä¸ªå…³é”®è®®é¢˜]
    - é‡è¦ç»“è®º: [åˆ—å‡ºé‡è¦å†³å®šå’Œç»“è®º]
    - å¾…åŠäº‹é¡¹: 
      - [ä»»åŠ¡1] è´Ÿè´£äºº: [å§“å] æˆªæ­¢æ—¶é—´: [æ—¥æœŸ]
      - [ä»»åŠ¡2] è´Ÿè´£äºº: [å§“å] æˆªæ­¢æ—¶é—´: [æ—¥æœŸ]
    
    ä¼šè®®è®°å½•å†…å®¹ï¼š
    {transcript[:5000]}  # é™åˆ¶é•¿åº¦
    """
    
    summary = deepseek_chat(summary_prompt, "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®è®°å½•åŠ©æ‰‹")
    return transcript, summary

def generate_news_report(style="æ­£å¼æŠ¥é“"):
    """ç”Ÿæˆä¼šè®®æ–°é—»æŠ¥é“"""
    prompt = f"""
    è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®æ‘˜è¦ç”Ÿæˆä¸€ç¯‡{style}é£æ ¼çš„æ–°é—»æŠ¥é“ï¼š
    
    {meeting_data.get('summary', '')}
    
    æŠ¥é“è¦æ±‚ï¼š
    1. æ ‡é¢˜é†’ç›®
    2. åŒ…å«ä¼šè®®åŸºæœ¬ä¿¡æ¯ï¼ˆæ—¶é—´ã€åœ°ç‚¹ã€å‚ä¼šäººå‘˜ï¼‰
    3. çªå‡ºä¼šè®®æˆæœå’Œé‡è¦å†³ç­–
    4. ä½¿ç”¨{style}é£æ ¼æ’°å†™
    """
    
    styles = {
        "æ­£å¼æŠ¥é“": "ä¸“ä¸šã€ä¸¥è°¨çš„æ–°é—»æŠ¥é“é£æ ¼",
        "ç®€æŠ¥æ‘˜è¦": "ç®€æ´æ˜äº†çš„è¦ç‚¹å¼æ€»ç»“",
        "ç¤¾äº¤åª’ä½“": "ç”ŸåŠ¨æ´»æ³¼çš„ç¤¾äº¤åª’ä½“é£æ ¼ï¼Œä½¿ç”¨è¡¨æƒ…ç¬¦å·å’Œè¯é¢˜æ ‡ç­¾"
    }
    
    return deepseek_chat(prompt, f"ä½ æ˜¯ä¸€åè®°è€…ï¼Œæ“…é•¿å†™{styles[style]}çš„ä¼šè®®æŠ¥é“")

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Soft(), title="DeepSeekä¼šè®®åŠ©æ‰‹") as app:
    gr.Markdown("# ğŸ™ï¸ DeepSeekä¼šè®®è®°å½•åŠ©æ‰‹")
    gr.Markdown("ä½¿ç”¨å›½äº§DeepSeek AIæŠ€æœ¯ï¼Œè‡ªåŠ¨ç”Ÿæˆä¼šè®®è®°å½•å’Œæ–°é—»æŠ¥é“")
    
    with gr.Tab("ä¸Šä¼ ä¼šè®®å½•éŸ³"):
        audio_input = gr.Audio(source="upload", type="filepath", label="ä¸Šä¼ å½•éŸ³æ–‡ä»¶")
        upload_btn = gr.Button("å¤„ç†ä¼šè®®å½•éŸ³", variant="primary")
    
    with gr.Tab("å®æ—¶ä¼šè®®è®°å½•"):
        with gr.Row():
            duration = gr.Slider(1, 600, value=60, label="å½•éŸ³æ—¶é•¿(ç§’)")
            record_btn = gr.Button("å¼€å§‹å½•éŸ³", variant="primary")
        record_output = gr.Audio(label="å½•éŸ³é¢„è§ˆ", interactive=False)
    
    with gr.Tab("ä¼šè®®ç»“æœ"):
        transcript = gr.Textbox(label="ä¼šè®®è½¬å½•æ–‡æœ¬", lines=10)
        summary = gr.Textbox(label="ä¼šè®®æ‘˜è¦", lines=10)
        
        with gr.Row():
            style = gr.Radio(
                choices=["æ­£å¼æŠ¥é“", "ç®€æŠ¥æ‘˜è¦", "ç¤¾äº¤åª’ä½“"],
                value="æ­£å¼æŠ¥é“",
                label="æ–°é—»é£æ ¼"
            )
            news_btn = gr.Button("ç”Ÿæˆæ–°é—»æŠ¥é“", variant="primary")
        news_report = gr.Textbox(label="ä¼šè®®æ–°é—»æŠ¥é“", lines=12)
    
    # äº‹ä»¶å¤„ç†
    upload_btn.click(
        fn=process_meeting,
        inputs=audio_input,
        outputs=[transcript, summary]
    )
    
    record_btn.click(
        fn=record_audio,
        inputs=duration,
        outputs=record_output
    )
    
    record_output.change(
        fn=lambda x: process_meeting(live_audio=x),
        inputs=record_output,
        outputs=[transcript, summary]
    )
    
    news_btn.click(
        fn=generate_news_report,
        inputs=style,
        outputs=news_report
    )

if __name__ == "__main__":
    app.launch()